{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import re\n",
    "import string\n",
    "import progressbar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import ipython_genutils\n",
    "from sklearn import utils\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.layers import Flatten\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1596753 entries, 0 to 1596752\n",
      "Data columns (total 2 columns):\n",
      "text      1596753 non-null object\n",
      "target    1596753 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 20 columns):\n",
      "_unit_id                        14640 non-null int64\n",
      "_golden                         14640 non-null bool\n",
      "_unit_state                     14640 non-null object\n",
      "_trusted_judgments              14640 non-null int64\n",
      "_last_judgment_at               14584 non-null object\n",
      "airline_sentiment               14640 non-null int64\n",
      "airline_sentiment:confidence    14640 non-null float64\n",
      "negativereason                  9178 non-null object\n",
      "negativereason:confidence       10522 non-null float64\n",
      "airline                         14640 non-null object\n",
      "airline_sentiment_gold          40 non-null object\n",
      "name                            14640 non-null object\n",
      "negativereason_gold             32 non-null object\n",
      "retweet_count                   14640 non-null int64\n",
      "text                            14640 non-null object\n",
      "tweet_coord                     1019 non-null object\n",
      "tweet_created                   14640 non-null object\n",
      "tweet_id                        14640 non-null float64\n",
      "tweet_location                  9907 non-null object\n",
      "user_timezone                   9820 non-null object\n",
      "dtypes: bool(1), float64(3), int64(4), object(12)\n",
      "memory usage: 2.1+ MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13871 entries, 0 to 13870\n",
      "Data columns (total 21 columns):\n",
      "id                           13871 non-null int64\n",
      "candidate                    13775 non-null object\n",
      "candidate_confidence         13871 non-null float64\n",
      "relevant_yn                  13871 non-null object\n",
      "relevant_yn_confidence       13871 non-null float64\n",
      "sentiment                    13871 non-null int64\n",
      "sentiment_confidence         13871 non-null float64\n",
      "subject_matter               13545 non-null object\n",
      "subject_matter_confidence    13871 non-null float64\n",
      "candidate_gold               28 non-null object\n",
      "name                         13871 non-null object\n",
      "relevant_yn_gold             32 non-null object\n",
      "retweet_count                13871 non-null int64\n",
      "sentiment_gold               15 non-null object\n",
      "subject_matter_gold          18 non-null object\n",
      "text                         13871 non-null object\n",
      "tweet_coord                  21 non-null object\n",
      "tweet_created                13871 non-null object\n",
      "tweet_id                     13871 non-null int64\n",
      "tweet_location               9959 non-null object\n",
      "user_timezone                9468 non-null object\n",
      "dtypes: float64(4), int64(4), object(13)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "# file 1\n",
    "dfct = pd.read_csv('data/clean_tweet.csv',index_col=0)\n",
    "dfct['target']= dfct['target'].map({0:0,4:2})\n",
    "dfct.dropna(inplace=True)\n",
    "dfct.reset_index(drop=True,inplace=True)\n",
    "dfct.info()\n",
    "print()\n",
    "\n",
    "#file 2\n",
    "airlinedf = pd.read_csv('data/airline.csv',encoding='ISO-8859-1')\n",
    "airlinedf['airline_sentiment'] = airlinedf['airline_sentiment'].map({'negative':0,'neutral':1,'positive':2})\n",
    "airlinedf.dropna()\n",
    "airlinedf.reset_index(drop=True,inplace=True)\n",
    "airlinedf.info()\n",
    "print()\n",
    "\n",
    "#file 3\n",
    "debatedf = pd.read_csv('data/debate.csv',encoding='ISO-8859-1')\n",
    "debatedf['sentiment']=debatedf['sentiment'].map({'Negative':0,'Neutral':1,'Positive':2})\n",
    "debatedf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1625264 entries, 0 to 1625263\n",
      "Data columns (total 2 columns):\n",
      "text      1625264 non-null object\n",
      "target    1625264 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# gabung data dari file\n",
    "textdf=dfct['text'].astype('str')\n",
    "textair=airlinedf['text'].astype('str')\n",
    "textdebate=debatedf['text'].astype('str')\n",
    "x=pd.concat([textdf,textair,textdebate])\n",
    "x.reset_index(drop=True,inplace=True)\n",
    "\n",
    "targetdf=dfct['target']\n",
    "targetair=airlinedf['airline_sentiment']\n",
    "targetdebate=debatedf['sentiment']\n",
    "y=pd.concat([targetdf,targetair,targetdebate])\n",
    "y.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df=pd.DataFrame({'text':x,'target':y})\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hapus emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  \n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets = [progressbar.Percentage(),progressbar.Bar(),\" Processed : \",progressbar.Counter(),\"  \",progressbar.ETA()]\n",
    "bar = progressbar.ProgressBar(widgets=widgets, max_value=len(df.index))\n",
    "bar.start()\n",
    "\n",
    "t=[]\n",
    "for index,row in bar(df.iterrows()):\n",
    "    t.append(remove_emoji(row['text']))\n",
    "df.text=t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweet cleaning\n",
    "tok=WordPunctTokenizer()\n",
    "t=[]\n",
    "for index,row in df.iterrows():\n",
    "    x=row[\"text\"]\n",
    "    # hapus rt\n",
    "    cl = re.sub(r'\\s*RT\\s*@[^:]*:.*', '', x)\n",
    "    cl = re.sub(r'\\s*rt\\s*@[^:]*:.*', '', cl)\n",
    "    # hapus mention\n",
    "    cl = re.sub(r'@[A-Za-z0-9]([^:\\s]+)+', '', cl)\n",
    "    # hapus link\n",
    "    cl = re.sub(r'https?://[A-Za-z0-9./]+', '', cl)\n",
    "    # hapus hashtag\n",
    "    cl = re.sub(r'(?:\\s|^)#[A-Za-z0-9\\-\\.\\_]+(?:\\s|$)', '', cl)\n",
    "    # kata ulang\n",
    "    cl = re.sub(r'\\w*\\d\\w*', '', cl)\n",
    "    cl = re.sub(r'\\b(\\w+)(\\1\\b)+', r'\\1', cl)\n",
    "    # hapus simbol\n",
    "    cl = re.sub(r'[^a-zA-Z]', ' ', cl)\n",
    "    # lower\n",
    "    cl=cl.lower()\n",
    "    # format teks \n",
    "    cl=tok.tokenize(cl)\n",
    "    cl=(\" \".join(cl))\n",
    "    t.append(cl)\n",
    "    #print(cl)\n",
    "df.text=t\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hapus row yg terdapat data kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1618059 entries, 0 to 1618058\n",
      "Data columns (total 2 columns):\n",
      "text      1618059 non-null object\n",
      "target    1618059 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# hapus data dgn missing value\n",
    "ex=''\n",
    "df=df[df.text != ex]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hapus stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset update facebook texting might cry result...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>behaving mad see</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0       awww bummer shoulda got david carr third day       0\n",
       "1  upset update facebook texting might cry result...       0\n",
       "2  dived many times ball managed save rest go bounds       0\n",
       "3                   whole body feels itchy like fire       0\n",
       "4                                   behaving mad see       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords\n",
    "stopword_ = set(stopwords.words('english'))\n",
    "t=[]\n",
    "c=0\n",
    "for index,row in df.iterrows():\n",
    "    tokens = word_tokenize(row['text'])\n",
    "    result = [i for i in tokens if not i in stopword_]\n",
    "    result=' '.join(result)\n",
    "    t.append(result)\n",
    "    if c%100000==0:\n",
    "        print('data processed : ',c)\n",
    "    c+=1\n",
    "df.text=t\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed :  0\n",
      "data processed :  100000\n",
      "data processed :  200000\n",
      "data processed :  300000\n",
      "data processed :  400000\n",
      "data processed :  500000\n",
      "data processed :  600000\n",
      "data processed :  700000\n",
      "data processed :  800000\n",
      "data processed :  900000\n",
      "data processed :  1000000\n",
      "data processed :  1100000\n",
      "data processed :  1200000\n",
      "data processed :  1300000\n",
      "data processed :  1400000\n",
      "data processed :  1500000\n",
      "data processed :  1600000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>behav mad see</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0       awww bummer shoulda got david carr third day       0\n",
       "1  upset updat facebook text might cri result sch...       0\n",
       "2       dive mani time ball manag save rest go bound       0\n",
       "3                    whole bodi feel itchi like fire       0\n",
       "4                                      behav mad see       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "stemmer= PorterStemmer()\n",
    "t=[]\n",
    "for index,row in df.iterrows():\n",
    "    result=[]\n",
    "    text = word_tokenize(row['text'])\n",
    "    for word in text:\n",
    "        result.append(stemmer.stem(word))\n",
    "    result=' '.join(result) \n",
    "    t.append(result)\n",
    "df.text=t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ke csv\n",
    "df.to_csv('clean_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
